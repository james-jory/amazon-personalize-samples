{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a Recommender <a class=\"anchor\" id=\"top\"></a>\n",
    "\n",
    "\n",
    "## Outline\n",
    "\n",
    "1. [Introduction](#intro)\n",
    "1. [Create a \"Top picks for you\" Recommender](#recommenders)\n",
    "1. [Evaluate recommenders](#eval)\n",
    "1. [Using Evaluation Metrics](#usemetrics)\n",
    "\n",
    "\n",
    "## Introduction <a class=\"anchor\" id=\"intro\"></a>\n",
    "\n",
    "In the previous notebook: [`02_Train_Personalize_Model_01_Data.ipynb`](02_Train_Personalize_Model_01_Data.ipynb) you prepared datasets that represent User interactions, and Media catalog data, and created Datasets in Amazon Personalize for this data.\n",
    "\n",
    "In this Notebook we will train a Domain Optimized Recommender that returns video recommendations. The goal is to recommend products that are relevant based on a particular user.\n",
    "\n",
    "\n",
    "## Define your Use Case <a class=\"anchor\" id=\"usecase\"></a>\n",
    "[Back to top](#top)\n",
    "\n",
    "There are a few guidelines for scoping a problem suitable for Amazon Personalize. We recommend the values below as a starting point, although the [official limits](https://docs.aws.amazon.com/personalize/latest/dg/limits.html) lie a little lower.\n",
    "\n",
    "* Authenticated users\n",
    "* At least 50 unique users\n",
    "* At least 100 unique items\n",
    "* At least 2 dozen interactions for each user \n",
    "\n",
    "Most of the time this is easily attainable, and if you are low in one category, you can often make up for it by having a larger number in another category.\n",
    "\n",
    "The user-item-iteraction data is key for getting started with the service. This means we need to look for use cases that generate that kind of data, a few common examples are:\n",
    "\n",
    "1. Video-on-demand applications\n",
    "1. E-commerce platforms\n",
    "\n",
    "Defining your use-case will inform what data and what type of data you need.\n",
    "\n",
    "### Train Models and create API's for recommendations\n",
    "\n",
    "In this section we will be creating Video on Demand Use Case Optimized Recommender for the following use case:\n",
    "\n",
    "1. [Top picks for you](https://docs.aws.amazon.com/personalize/latest/dg/VIDEO_ON_DEMAND-use-cases.html#top-picks-use-case): personalized content recommendations for a user that you specify. With this use case, Amazon Personalize automatically filters videos the user watched based on the userId that you specify and Watch events.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to the previous notebook, start by importing the relevant packages, and set up a connection to Amazon Personalize using the SDK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from time import sleep\n",
    "import json\n",
    "from datetime import datetime\n",
    "import uuid\n",
    "import random\n",
    "import boto3\n",
    "import botocore\n",
    "from botocore.exceptions import ClientError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrive the saved variables from the previous notebook\n",
    "%store -r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure the SDK to Personalize:\n",
    "personalize = boto3.client('personalize')\n",
    "personalize_runtime = boto3.client('personalize-runtime')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to train your Use Case Optimized Recommender\n",
    "\n",
    "Below we will walk you through the steps we used to create these resources. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ready... Set... Train! :\n",
    "\n",
    "Now that the data is imported and ready for use, we will create Video on Demand Use Case Optimized Recommender for the following use cases:\n",
    "\n",
    "1. [Top picks for you](https://docs.aws.amazon.com/personalize/latest/dg/VIDEO_ON_DEMAND-use-cases.html#top-picks-use-case): personalized content recommendations for a user that you specify. With this use case, Amazon Personalize automatically filters videos the user watched based on the userId that you specify and Watch events.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a \"Top picks for you\" Recommender <a class=\"anchor\" id=\"recommenders\"></a>\n",
    "[Back to top](#top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll create a pre-configured VIDEO_ON_DEMAND Recommender that matches our use case. \n",
    "\n",
    "Each domain has different use cases. When you create a recommender you create it for a specific use case, and each use case has different requirements for getting recommendations.\n",
    "\n",
    "Let us look at the recommenders supported for the VIDEO_ON_DEMAND domain:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "available_recipes = personalize.list_recipes(domain='VIDEO_ON_DEMAND')\n",
    "display_available_recipes = available_recipes ['recipes']\n",
    "available_recipes = personalize.list_recipes(domain='VIDEO_ON_DEMAND',nextToken=available_recipes['nextToken'])#paging to get the rest of the recipes \n",
    "display_available_recipes = display_available_recipes + available_recipes['recipes']\n",
    "display(display_available_recipes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to create a recommender of the type \"Top picks for you\". This type of recommender offers personalized streaming content recommendations for a user that you specify. With this use case, Amazon Personalize automatically filters videos the user watched based on the userId that you specify and Watch events.\n",
    "\n",
    "We will add:\n",
    "\n",
    "```python\n",
    "recommenderConfig = {\"enableMetadataWithRecommendations\": True}\n",
    "```\n",
    "in order to include metadata when you getRecommendations request. This is not required, but if not enabled, the recommender will only return the itemIds of the recommended items. You can find more about this feature in the documentation ([domain](https://docs.aws.amazon.com/personalize/latest/dg/creating-recommenders.html))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    create_recommender_response = personalize.create_recommender(\n",
    "        name = recommender_top_picks_for_you_name,\n",
    "        recipeArn = 'arn:aws:personalize:::recipe/aws-vod-top-picks',\n",
    "        datasetGroupArn = workshop_dataset_group_arn,\n",
    "        recommenderConfig = {\"enableMetadataWithRecommendations\": True}\n",
    "    )\n",
    "    workshop_recommender_top_picks_arn = create_recommender_response[\"recommenderArn\"]\n",
    "    \n",
    "    print (json.dumps(create_recommender_response))\n",
    "    print ('\\nCreating the Top Picks For You recommender with workshop_recommender_top_picks_arn = {}'.format(workshop_recommender_top_picks_arn))\n",
    "    \n",
    "except personalize.exceptions.ResourceAlreadyExistsException as e:\n",
    "    workshop_recommender_top_picks_arn =  'arn:aws:personalize:'+region+':'+account_id+':recommender/'+recommender_top_picks_for_you_name\n",
    "    print('The Top Picks For You recommender {} already exists.'.format(workshop_recommender_top_picks_arn))\n",
    "    print ('\\nWe will be using the existing Top Picks For You recommender with workshop_recommender_top_picks_arn = {}'.format(workshop_recommender_top_picks_arn))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View recommender creation status\n",
    "\n",
    "We set up a loop to see the status of the recommender creation. This can take more than 60 minutes to train. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_time = time.time() + 10*60*60 # 10 hours\n",
    "while time.time() < max_time:\n",
    "\n",
    "    # Recommender top_picks_for_you\n",
    "    version_response = personalize.describe_recommender(\n",
    "        recommenderArn = workshop_recommender_top_picks_arn\n",
    "    )\n",
    "    status_top_picks = version_response[\"recommender\"][\"status\"]\n",
    "\n",
    "    if status_top_picks == \"ACTIVE\":\n",
    "        print(\"Build succeeded for {}\".format(workshop_recommender_top_picks_arn))\n",
    "    elif status_top_picks == \"CREATE FAILED\":\n",
    "        print(\"Build failed for {}\".format(workshop_recommender_top_picks_arn))\n",
    "        break\n",
    "\n",
    "    if not status_top_picks == \"ACTIVE\":\n",
    "        print(\"The Top Picks for You recommender build is still in progress\")\n",
    "    else:\n",
    "        print(\"The Top Picks for You recommender is ACTIVE\")\n",
    "\n",
    "    if status_top_picks == 'ACTIVE':\n",
    "        break\n",
    "    print()\n",
    "    time.sleep(60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate recommenders <a class=\"anchor\" id=\"eval\"></a>\n",
    "[Back to top](#top)\n",
    "\n",
    "Personalize calculates these metrics based on a subset of the training data. The image below illustrates how Personalize splits the data. Given 10 users, with 10 interactions each (a circle represents an interaction), the interactions are ordered from oldest to newest based on the timestamp. Personalize uses all of the interaction data from 90% of the users (blue circles) to train the solution version, and the remaining 10% for evaluation. For each of the users in the remaining 10%, 90% of their interaction data (green circles) is used as input for the call to the trained model. The remaining 10% of their data (orange circle) is compared to the output produced by the model and used to calculate the evaluation metrics.\n",
    "\n",
    "![personalize metrics](./images/personalize_metrics.png)\n",
    "\n",
    "We recommend reading [the documentation](https://docs.aws.amazon.com/personalize/latest/dg/working-with-training-metrics.html) to understand the metrics, but we have also copied parts of the documentation below for convenience.\n",
    "\n",
    "You need to understand the following terms regarding evaluation in Personalize:\n",
    "\n",
    "* *Relevant recommendation* refers to a recommendation that matches a value in the testing data for the particular user.\n",
    "* *Rank* refers to the position of a recommended item in the list of recommendations. Position 1 (the top of the list) is presumed to be the most relevant to the user.\n",
    "* *Query* refers to the internal equivalent of a GetRecommendations call.\n",
    "\n",
    "The metrics produced by Personalize are:\n",
    "* **coverage**: The proportion of unique recommended items from all queries out of the total number of unique items in the training data (includes both the Items and Interactions datasets).\n",
    "* **mean_reciprocal_rank_at_25**: The [mean of the reciprocal ranks](https://en.wikipedia.org/wiki/Mean_reciprocal_rank) of the first relevant recommendation out of the top 25 recommendations over all queries. This metric is appropriate if you're interested in the single highest ranked recommendation.\n",
    "* **normalized_discounted_cumulative_gain_at_K**: Discounted gain assumes that recommendations lower on a list of recommendations are less relevant than higher recommendations. Therefore, each recommendation is discounted (given a lower weight) by a factor dependent on its position. To produce the [cumulative discounted gain](https://en.wikipedia.org/wiki/Discounted_cumulative_gain) (DCG) at K, each relevant discounted recommendation in the top K recommendations is summed together. The normalized discounted cumulative gain (NDCG) is the DCG divided by the ideal DCG such that NDCG is between 0 - 1. (The ideal DCG is where the top K recommendations are sorted by relevance.) Amazon Personalize uses a weighting factor of 1/log(1 + position), where the top of the list is position 1. This metric rewards relevant items that appear near the top of the list, because the top of a list usually draws more attention.\n",
    "* **precision_at_K**: The number of relevant recommendations out of the top K recommendations divided by K. This metric rewards precise recommendation of the relevant items.\n",
    "\n",
    "Let's take a look at the evaluation metrics for the recommender."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \"Top Picks for You\" recommender metrics\n",
    "\n",
    "Retrieve the evaluation metrics for the \"Top Picks For you\" Recommender."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workshop_recommender_top_picks_metrics_response = personalize.describe_recommender(\n",
    "    recommenderArn = workshop_recommender_top_picks_arn\n",
    ")\n",
    "\n",
    "status_top_picks = version_response[\"recommender\"][\"status\"]\n",
    "\n",
    "if status_top_picks == \"ACTIVE\":\n",
    "    for metric in workshop_recommender_top_picks_metrics_response['recommender']['modelMetrics']:\n",
    "        print (\"{}: {}\".format(metric, workshop_recommender_top_picks_metrics_response['recommender']['modelMetrics'][metric]))\n",
    "elif status_top_picks == \"CREATE FAILED\":\n",
    "    print(\"Build failed for {}\".format(workshop_recommender_top_picks_arn))\n",
    "elif not status_top_picks == \"ACTIVE\":\n",
    "    print(\"The Top Picks for You recommender build is still in progress\")\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Using evaluation metrics <a class=\"anchor\" id=\"usemetrics\"></a>\n",
    "[Back to top](#top)\n",
    "\n",
    "It is important to use evaluation metrics carefully. There are a number of factors to keep in mind.\n",
    "\n",
    "* If there is an existing recommendation system in place, this will have influenced the user's interaction history which you use to train your new solutions. This means the evaluation metrics are biased to favor the existing solution. If you work to push the evaluation metrics to match or exceed the existing solution, you may just be pushing the User Personalization to behave like the existing solution and might not end up with something better.\n",
    "\n",
    "\n",
    "Keeping in mind these factors, the evaluation metrics produced by Personalize are generally useful for two cases:\n",
    "1. Comparing the performance of solution versions trained on the same recipe, but with different values for the hyperparameters and features (impression data etc)\n",
    "1. Comparing the performance of solution versions trained on different recipes. Here also keep in mind that the recipes answer different use cases and comparing them to each other might not make sense in your solution.\n",
    "\n",
    "Properly evaluating a recommendation system is always best done through A/B testing while measuring actual business outcomes. Since recommendations generated by a system usually influence the user behavior which it is based on, it is better to run small experiments and apply A/B testing for longer periods of time. Over time, the bias from the existing model will fade."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %store dataset_dir\n",
    "%store data_dir\n",
    "%store interactions_filename\n",
    "%store items_filename\n",
    "%store workshop_dataset_group_arn\n",
    "%store workshop_recommender_top_picks_arn\n",
    "%store region\n",
    "%store account_id\n",
    "%store role_name\n",
    "%store role_arn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Go to the next notebook `04_Personalized_Emails_with_Amazon_Personalize_and_Generative_AI.ipynb`](04_Personalized_Emails_with_Amazon_Personalize_and_Generative_AI.ipynb) to continue."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
